{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55489e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "Found cached dataset cnn_dailymail (/home/ubuntu/.cache/huggingface/datasets/ccdv___cnn_dailymail/3.0.0/3.0.0/0107f7388b5c6fae455a5661bcd134fc22da53ea75852027040d8d1e997f101f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a89b4777c36b41a78830f2be19699100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "raw_dataset = load_dataset('ccdv/cnn_dailymail', '3.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14f65368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 287113\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 13368\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 11490\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97594d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria. Obama sent a letter to the heads of the House and Senate on Saturday night, hours afte\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset['train'][0]['article'][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7e4ecad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's official: U.S. President Barack Obama wan...</td>\n",
       "      <td>Syrian official: Obama climbed to the top of t...</td>\n",
       "      <td>0001d1afc246a7964130f43ae940af6bc6c57f01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) -- Usain Bolt rounded off the world cham...</td>\n",
       "      <td>Usain Bolt wins third gold of world championsh...</td>\n",
       "      <td>0002095e55fcbd3a2f366d9bf92a95433dc305ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kansas City, Missouri (CNN) -- The General Ser...</td>\n",
       "      <td>The employee in agency's Kansas City office is...</td>\n",
       "      <td>00027e965c8264c35cc1bc55556db388da82b07f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Los Angeles (CNN) -- A medical doctor in Vanco...</td>\n",
       "      <td>NEW: A Canadian doctor says she was part of a ...</td>\n",
       "      <td>0002c17436637c4fe1837c935c04de47adb18e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(CNN) -- Police arrested another teen Thursday...</td>\n",
       "      <td>Another arrest made in gang rape outside Calif...</td>\n",
       "      <td>0003ad6ef0c37534f80b55b4235108024b407f0b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287108</th>\n",
       "      <td>Tiger Woods’s frustration at the lamentable st...</td>\n",
       "      <td>Woods said: ’Guys, give me a little f***ing sp...</td>\n",
       "      <td>fffdfb56fdf1a12d364562cc2b9b1d4de7481dee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287109</th>\n",
       "      <td>By . Mark Duell . Last updated at 4:07 PM on 2...</td>\n",
       "      <td>13 sailors died in 1804 after explosives ship ...</td>\n",
       "      <td>fffeecb8690b85de8c3faed80adbc7a978f9ae2a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287110</th>\n",
       "      <td>Suicide: Troll victim Hannah Smith, 14, killed...</td>\n",
       "      <td>Hannah Smith's father says Ask.fm's safety cha...</td>\n",
       "      <td>ffff5231e4c71544bc6c97015cdb16c60e42b3f4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287111</th>\n",
       "      <td>By . Victoria Woollaston and Mark Prigg . PUBL...</td>\n",
       "      <td>A test version of Windows 8.1 is available to ...</td>\n",
       "      <td>ffff924b14a8d82058b6c1c5368ff1113c1632af</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287112</th>\n",
       "      <td>Under fire Australian Defence Minister David J...</td>\n",
       "      <td>Defence Minister David Johnston said his 'I wo...</td>\n",
       "      <td>ffffd563a96104f5cf4493cfa701a65f31b06abf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287113 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  article  \\\n",
       "0       It's official: U.S. President Barack Obama wan...   \n",
       "1       (CNN) -- Usain Bolt rounded off the world cham...   \n",
       "2       Kansas City, Missouri (CNN) -- The General Ser...   \n",
       "3       Los Angeles (CNN) -- A medical doctor in Vanco...   \n",
       "4       (CNN) -- Police arrested another teen Thursday...   \n",
       "...                                                   ...   \n",
       "287108  Tiger Woods’s frustration at the lamentable st...   \n",
       "287109  By . Mark Duell . Last updated at 4:07 PM on 2...   \n",
       "287110  Suicide: Troll victim Hannah Smith, 14, killed...   \n",
       "287111  By . Victoria Woollaston and Mark Prigg . PUBL...   \n",
       "287112  Under fire Australian Defence Minister David J...   \n",
       "\n",
       "                                               highlights  \\\n",
       "0       Syrian official: Obama climbed to the top of t...   \n",
       "1       Usain Bolt wins third gold of world championsh...   \n",
       "2       The employee in agency's Kansas City office is...   \n",
       "3       NEW: A Canadian doctor says she was part of a ...   \n",
       "4       Another arrest made in gang rape outside Calif...   \n",
       "...                                                   ...   \n",
       "287108  Woods said: ’Guys, give me a little f***ing sp...   \n",
       "287109  13 sailors died in 1804 after explosives ship ...   \n",
       "287110  Hannah Smith's father says Ask.fm's safety cha...   \n",
       "287111  A test version of Windows 8.1 is available to ...   \n",
       "287112  Defence Minister David Johnston said his 'I wo...   \n",
       "\n",
       "                                              id  \n",
       "0       0001d1afc246a7964130f43ae940af6bc6c57f01  \n",
       "1       0002095e55fcbd3a2f366d9bf92a95433dc305ef  \n",
       "2       00027e965c8264c35cc1bc55556db388da82b07f  \n",
       "3       0002c17436637c4fe1837c935c04de47adb18e9a  \n",
       "4       0003ad6ef0c37534f80b55b4235108024b407f0b  \n",
       "...                                          ...  \n",
       "287108  fffdfb56fdf1a12d364562cc2b9b1d4de7481dee  \n",
       "287109  fffeecb8690b85de8c3faed80adbc7a978f9ae2a  \n",
       "287110  ffff5231e4c71544bc6c97015cdb16c60e42b3f4  \n",
       "287111  ffff924b14a8d82058b6c1c5368ff1113c1632af  \n",
       "287112  ffffd563a96104f5cf4493cfa701a65f31b06abf  \n",
       "\n",
       "[287113 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdec78e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_dataset = DatasetDict(\n",
    "    {\n",
    "        \"train\": raw_dataset['train'].select(range(50000)).shuffle(),\n",
    "        \"valid\": raw_dataset['test'].select(range(5000)).shuffle()\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f0bc79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36c40ebb",
   "metadata": {},
   "source": [
    "## tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87d9e725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b378eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_corpus(ds):\n",
    "    return(\n",
    "        ds[i:i+1000]['article'] for i in range(0, len(ds), 1000)\n",
    "    )\n",
    "\n",
    "\n",
    "training_corpus = get_training_corpus(raw_dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc3fd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer = tokenizer.train_new_from_iterator(training_corpus, vocab_size=50257)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "013ec5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It',\n",
       " \"'s\",\n",
       " 'Ġofficial',\n",
       " ':',\n",
       " 'ĠU',\n",
       " '.',\n",
       " 'S',\n",
       " '.',\n",
       " 'ĠPresident',\n",
       " 'ĠBarack',\n",
       " 'ĠObama',\n",
       " 'Ġwants',\n",
       " 'Ġlawmakers',\n",
       " 'Ġto',\n",
       " 'Ġweigh',\n",
       " 'Ġin',\n",
       " 'Ġon',\n",
       " 'Ġwhether',\n",
       " 'Ġto',\n",
       " 'Ġuse',\n",
       " 'Ġmilitary',\n",
       " 'Ġforce',\n",
       " 'Ġin',\n",
       " 'ĠSyria']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = \"It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria\"\n",
    "\n",
    "tokenizer.tokenize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c57835d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [868, 345, 1061, 26, 458, 14, 51, 14, 1497, 4149, 1288, 2880, 8505, 280, 6284, 285, 316, 1714, 280, 1321, 1681, 2692, 285, 2730], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'length': [24]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(sample_text, return_length=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b9e8168",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 128\n",
    "\n",
    "def tokenize(batch):\n",
    "    outputs = tokenizer(\n",
    "        batch['article'],\n",
    "        max_length=context_length,\n",
    "        truncation=True,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True\n",
    "    )\n",
    "    \n",
    "    input_batch = []\n",
    "    for length, input_ids in zip(outputs['length'], outputs['input_ids']):\n",
    "        if length==context_length:\n",
    "            input_batch.append(input_ids)\n",
    "    return {\"input_ids\": input_batch}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9864fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = sampled_dataset.map(tokenize, batched=True, remove_columns=raw_dataset['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596122d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdd38c8f",
   "metadata": {},
   "source": [
    "## load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecc2b5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaConfig {\n",
       "  \"bos_token_id\": 1,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 4096,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 11008,\n",
       "  \"max_position_embeddings\": 2048,\n",
       "  \"model_type\": \"llama\",\n",
       "  \"num_attention_heads\": 32,\n",
       "  \"num_hidden_layers\": 32,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"rms_norm_eps\": 1e-06,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"transformers_version\": \"4.28.0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32000\n",
       "}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import LlamaConfig\n",
    "\n",
    "configuration = LlamaConfig()\n",
    "\n",
    "configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b388dce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50256, 50256, 50257)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.bos_token_id, tokenizer.eos_token_id, tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9648d6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = LlamaConfig(**{\n",
    "  \"bos_token_id\": 50256,\n",
    "  \"eos_token_id\": 50256,\n",
    "  \"hidden_act\": \"silu\",\n",
    "  \"hidden_size\": 512,\n",
    "  \"initializer_range\": 0.02,\n",
    "  \"intermediate_size\": 1376,\n",
    "  \"max_position_embeddings\": 128,\n",
    "  \"model_type\": \"llama\",\n",
    "  \"num_attention_heads\": 4,\n",
    "  \"num_hidden_layers\": 4,\n",
    "  \"pad_token_id\": 0,\n",
    "  \"rms_norm_eps\": 1e-06,\n",
    "  \"tie_word_embeddings\": False,\n",
    "  \"transformers_version\": \"4.28.0\",\n",
    "  \"use_cache\": True,\n",
    "  \"vocab_size\": 50257\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8680f44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(50257, 512, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=512, out_features=1376, bias=False)\n",
       "          (down_proj): Linear(in_features=1376, out_features=512, bias=False)\n",
       "          (up_proj): Linear(in_features=512, out_features=1376, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import LlamaForCausalLM\n",
    "\n",
    "model = LlamaForCausalLM(configuration)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "418242ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb62f7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94e0a7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1026,   338,  1743,    25,   471,    13,    50,    13,  1992,  8732,\n",
       "          2486,  3382, 10191,   284, 10164,   287,   319,  1771,   284,   779,\n",
       "          2422,  2700,   287,   220,  8229,  8229,  8229,  8229,  8229,  8229,\n",
       "         45936, 45936, 45936, 45936, 45936, 45936, 45936, 45936, 45936, 45936,\n",
       "         45936,  7907,  7907,  7907,  7907, 45827, 29700,  7907, 45827, 19297]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in \"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "inputs.to(device)\n",
    "\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=50)\n",
    "generate_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77d55bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in  Return Return Return Return Return Return Humane Humane Humane Humane Humane Humane Humane Humane Humane Humane Humane captured captured captured captured Inspiredinders captured Inspired Roosevelt\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27ee05f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "924b02b2",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5fed72a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "05695613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: torch.Size([3, 128])\n",
      "attention_mask: torch.Size([3, 128])\n",
      "labels: torch.Size([3, 128])\n"
     ]
    }
   ],
   "source": [
    "out = data_collator([tokenized_datasets['train'][i] for i in range(3)])\n",
    "\n",
    "for key in out:\n",
    "    print(f\"{key}: {out[key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d2f272d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    7, 18474,     8,  1377,  1649,   257,  3052,   326,  3667,   517,\n",
       "           621,   257,  2063,    12, 24540,  9651,  9692,  3011, 19957,    11]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " tensor([    7, 18474,     8,  1377,  1649,   257,  3052,   326,  3667,   517,\n",
       "           621,   257,  2063,    12, 24540,  9651,  9692,  3011, 19957,    11]))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['input_ids'][0][:20], out['attention_mask'][0][:20], out['labels'][0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1063853d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "92c33124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 32\n",
    "logging_steps = 1000\n",
    "learning_rate=5e-4\n",
    "num_epochs=1\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir='newsllama',\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=logging_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    save_steps=logging_steps,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.1,\n",
    "    warmup_steps=logging_steps,\n",
    "    lr_scheduler_type='cosine',\n",
    "    learning_rate=5e-4,\n",
    "    fp16=True,\n",
    "    push_to_hub=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "397824ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['valid']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcf2e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24844402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4614426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe4b4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7ee4d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1026,   338,  1743,    25,   471,    13,    50,    13,  1992,  8732,\n",
       "          2486,  3382, 10191,   284, 10164,   287,   319,  1771,   284,   779,\n",
       "          2422,  2700,   287,   220,  8229,  8229,  8229,  8229,  8229,  8229,\n",
       "         45936, 45936, 45936, 45936, 45936, 45936, 45936, 45936, 45936, 45936,\n",
       "         45936,  7907,  7907,  7907,  7907, 45827, 29700,  7907, 45827, 19297]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in \"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "inputs.to(device)\n",
    "\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=50)\n",
    "generate_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad640098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in  Return Return Return Return Return Return Humane Humane Humane Humane Humane Humane Humane Humane Humane Humane Humane captured captured captured captured Inspiredinders captured Inspired Roosevelt\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c0e1273e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It\\'s official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in the United States. \"We are not going to be a very good thing,\" he said. \"We are not going to be able'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in\"\"\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs.to(\"cuda:0\")\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=50)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "de7889d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Shall I compare thee to a summer’s day?\\nThou art more lovely and more temperate:\\nRough winds do shake the world's most important-time world. The world's most important-time world is the first\""
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Shall I compare thee to a summer’s day?\n",
    "Thou art more lovely and more temperate:\n",
    "Rough winds do shake the\"\"\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs.to(\"cuda:0\")\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=50)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "523c2855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As a scientific endeavor, machine learning grew out of the quest for artificial intelligence (AI). In the early days of AI as an academic discipline, some researchers were interested in the country\\'s capital. The U.S. government has been a \"a'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"As a scientific endeavor, machine learning grew out of the quest for artificial intelligence (AI). In the early days of AI as an academic discipline, some researchers were interested in\"\"\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs.to(\"cuda:0\")\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=50)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3973f430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989504b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94814a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7cdb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8c2e26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3be4a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5145ce53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a5dc929",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f116be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dcf1758d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: torch.Size([3, 128])\n",
      "attention_mask: torch.Size([3, 128])\n",
      "labels: torch.Size([3, 128])\n"
     ]
    }
   ],
   "source": [
    "out = data_collator([tokenized_datasets['train'][i] for i in range(3)])\n",
    "\n",
    "for key in out:\n",
    "    print(f\"{key}: {out[key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2feb25df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    7, 18474,     8,  1377,  1649,   257,  3052,   326,  3667,   517,\n",
       "           621,   257,  2063,    12, 24540,  9651,  9692,  3011, 19957,    11]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " tensor([    7, 18474,     8,  1377,  1649,   257,  3052,   326,  3667,   517,\n",
       "           621,   257,  2063,    12, 24540,  9651,  9692,  3011, 19957,    11]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['input_ids'][0][:20], out['attention_mask'][0][:20], out['labels'][0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e91aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3850e458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4146cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size=32\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"newsllama\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=5_00,\n",
    "    logging_steps=5_00,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.1,\n",
    "    warmup_steps=1_000,\n",
    "    lr_scheduler_type='cosine',\n",
    "    learning_rate=5e-4,\n",
    "    save_steps=5_000,\n",
    "    fp16=True,\n",
    "    push_to_hub=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d710b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['valid']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a803ae50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1158' max='1158' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1158/1158 08:03, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1158, training_loss=8.999320285513816, metrics={'train_runtime': 483.6832, 'train_samples_per_second': 613.126, 'train_steps_per_second': 2.394, 'total_flos': 8973058761031680.0, 'train_loss': 8.999320285513816, 'epoch': 1.0})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6776dc3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It\\'s official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in the United States. The U.S. government has said the United States is a \"to-to-to-to-to'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in\"\"\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs.to(\"cuda:0\")\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(inputs.input_ids, cmax_length=50)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4b4ae0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Shall I compare thee to a summer’s day?\\nThou art more lovely and more temperate:\\nRough winds do shake the same-sex marriage. The other is the first time the world's most important-time world\""
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Shall I compare thee to a summer’s day?\n",
    "Thou art more lovely and more temperate:\n",
    "Rough winds do shake the\"\"\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs.to(\"cuda:0\")\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=50)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8fa7d6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As a scientific endeavor, machine learning grew out of the quest for artificial intelligence (AI). In the early days of AI as an academic discipline, some researchers were interested in the country\\'s capital. The U.S. government has been a \"very'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"As a scientific endeavor, machine learning grew out of the quest for artificial intelligence (AI). In the early days of AI as an academic discipline, some researchers were interested in\"\"\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs.to(\"cuda:0\")\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=50)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea48640e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24336f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205ad40b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81907c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218ee5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2908ca19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Some implementations of machine learning use data and neural networks. The new data are also available. The new data are also available. The new data are also available. The most important of the most important countries in the country's countries, and the United States\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Some implementations of machine learning use data and neural networks\"\"\"\n",
    "\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "inputs.to(device)\n",
    "\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=50)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9918c7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Shall I compare thee to a summer’s day?\\nThou art more lovely and more temperate:\\nRough winds do shake the darling buds of May, and the other of the world's most of the world's most of\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Shall I compare thee to a summer’s day?\n",
    "Thou art more lovely and more temperate:\n",
    "Rough winds do shake the darling buds of May,\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "inputs.to(device)\n",
    "\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=50)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e56021bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It\\'s official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in  \"The United States and the United States of the country\\'s most of the country\\'s most of the country\\'s most of the country'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in \"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "inputs.to(device)\n",
    "\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=50)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
